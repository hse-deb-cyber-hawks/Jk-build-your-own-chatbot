{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Interact with deployed LLM via python \n",
    "\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Explore different techniques to interact with the deployed LLM.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "1. Use Request libaray (HTTP Client) and send a POST request to interact with the LLM: [How To](https://requests.readthedocs.io/en/latest/user/quickstart/#make-a-request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a class of machine learning algorithms that can create new data samples or text based on patterns and structures learned from existing data, often producing highly realistic and diverse outputs. Unlike traditional machine learning models, generative AI uses complex neural networks to generate novel content, such as images, videos, music, and even entire stories, without being explicitly programmed for a specific task."
     ]
    }
   ],
   "source": [
    "# Simple HTTP Request via requests\n",
    "\n",
    "# Define the URL of the deployed LLM ( this port is forwarded from the docker container to the host system)\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Define the prompt as json\n",
    "body_json = {\n",
    "    \"model\": model,\n",
    "    \"prompt\": \"Describe Generative AI in two sentences.\"\n",
    "}\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# HINT: Send the POST request using the json body\n",
    "response = requests.post(url, json=body_json)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Process the response\n",
    "    response_text = response.text\n",
    "\n",
    "    # Convert each line to json\n",
    "    response_lines = response_text.splitlines()\n",
    "    response_json = [json.loads(line) for line in response_lines]\n",
    "    for line in response_json:\n",
    "        # Print the response. No line break\n",
    "        print(line[\"response\"], end=\"\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Description:**\n",
    "\n",
    "2. Use Ollama python library to interact with the LLM: [How To](https://pypi.org/project/ollama/)\n",
    "\n",
    "- First use method ``ollama.chat(...)``\n",
    "- First use method ``ollama.chat(...)`` with ``stream=True``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI is a subfield of artificial intelligence that enables machines to create original content, such as text, images, and music, using patterns and algorithms learned from existing data or training examples. By generating new content that resembles the style of human-provided examples, generative AI can perform tasks like image editing, chatbot generation, and even creative writing, but it often lacks the nuance and emotional depth found in human-generated content.\n"
     ]
    }
   ],
   "source": [
    "# API Call via ollama\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe Generative AI in two sentences.\"}\n",
    "]\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a type of artificial intelligence that can create original content, such as text, images, or music, by generating new data based on patterns and associations learned from existing data. Unlike traditional machine learning models that focus on predicting outcomes, generative AI systems aim to produce novel and realistic outputs that resemble the real world, often with high levels of creativity and nuance."
     ]
    }
   ],
   "source": [
    "# Streaming API Call via ollama\n",
    "\n",
    "# Response streaming can be enabled by setting stream=True, \n",
    "# modifying function calls to return a Python generator where each part is an object in the stream.\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk[\"message\"][\"content\"], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Experimenting with Prompt Techniques\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Objective: Explore different prompt techniques (Zero Shot, One Shot, and Few Shot) by sending different types of prompts to the LLM.\n",
    "\n",
    "![image](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QSpK--jqPiUU_OHuZvtUWA.png)\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "1. Create three prompts for a sentiment analysis task: a Zero Shot prompt, a One Shot prompt, and a Few Shot prompt. Use the examples from the table above.\n",
    "2. Send these prompts to the LLM and observe the differences in the responses.\n",
    "3. Compare and discuss the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Zero-Shot Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Classify this review: I loved this movie! Sentiment:\n",
      "\n",
      "Model Output:\n",
      "The sentiment of this review is extremely positive.\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "--- One-Shot Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Classify this review: I loved this movie! Sentiment: Positive\n",
      "Classify this review: I don't like this chair. Sentiment:\n",
      "\n",
      "Model Output:\n",
      "For the first review, \"I loved this movie,\" the sentiment is overwhelmingly positive.\n",
      "\n",
      "For the second review, \"I don't like this chair,\" the sentiment is negative.\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "--- Few-Shot Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Classify this review: I loved this movie! Sentiment: Positive\n",
      "Classify this review: I don't like this chair. Sentiment: Negative\n",
      "Classify this review: Who would use this product? Sentiment:\n",
      "\n",
      "Model Output:\n",
      "Based on the content, here are my classifications:\n",
      "\n",
      "1. \"I loved this movie!\"\n",
      "   - Sentiment: Positive\n",
      "2. \"I don't like this chair.\"\n",
      "   - Sentiment: Negative (Note: This one is a very brief and straightforward statement without any descriptive language or emotional tone.)\n",
      "3. \"Who would use this product?\"\n",
      "   - Sentiment: Neutral/Negative (This review seems to be more of an inquiry about the target audience or market for the product, rather than expressing a strong sentiment.)\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ADD HERE YOUR PROMPTS\n",
    "\n",
    "zero_shot_prompt = \"\"\"Classify this review: I loved this movie! Sentiment:\"\"\"\n",
    "\n",
    "one_shot_prompt =(\n",
    "    'Classify this review: I loved this movie! Sentiment: Positive\\n'\n",
    "    \"Classify this review: I don't like this chair. Sentiment:\"\n",
    ")\n",
    "\n",
    "few_shot_prompt = (\n",
    "    'Classify this review: I loved this movie! Sentiment: Positive\\n'\n",
    "    \"Classify this review: I don't like this chair. Sentiment: Negative\\n\"\n",
    "    'Classify this review: Who would use this product? Sentiment:'\n",
    ")\n",
    "\n",
    "# Stream the responses and print them\n",
    "for idx, prompt in enumerate([zero_shot_prompt, one_shot_prompt, few_shot_prompt]):\n",
    "    prompt_type = [\"Zero-Shot\", \"One-Shot\", \"Few-Shot\"][idx]\n",
    "    print(f\"\\n--- {prompt_type} Prompt ---\\n\")\n",
    "    print(f\"User Prompt:\\n{prompt}\\n\")\n",
    "    \n",
    "    stream = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    print(\"Model Output:\")\n",
    "    for chunk in stream:\n",
    "        print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "    print(\"\\n-----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Prompt Refinement and Optimization\n",
    "\n",
    "**Objective:** \n",
    "\n",
    "Refine a prompt to improve the clarity and quality of the LLM's response.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Start with a basic prompt asking the LLM to summarize a paragraph.\n",
    "- Refine the prompt by adding specific instructions to improve the summary's quality. (Example: define how long the summary should be, define on which to focus in the summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Original Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Summarize the following paragraph: Generative AI is a field of artificial intelligence focused on creating new content based on patterns learned from existing data. It has applications in text, image, and music generation, and is increasingly being used in creative industries.\n",
      "\n",
      "Model Output:\n",
      "Here's a summary of the paragraph:\n",
      "\n",
      "Generative AI creates new content by analyzing patterns from existing data, such as text, images, or music, and uses that knowledge to produce original works. It has applications across various fields, including creative industries.\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "--- Refined Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Summarize the following paragraph in 2 concise sentences, focusing on the main goal of Generative AI and its key application areas. Avoid repeating the original phrasing and keep the tone informative and professional.\n",
      "\n",
      "Paragraph: Generative AI is a field of artificial intelligence focused on creating new content based on patterns learned from existing data. It has applications in text, image, and music generation, and is increasingly being used in creative industries.\n",
      "\n",
      "Model Output:\n",
      "Here is a 2-sentence summary:\n",
      "\n",
      "Generative AI aims to create novel content by leveraging patterns found in existing datasets. This field's diverse applications span across various domains, including but not limited to, creative industries such as writing, art, and music.\n",
      "\n",
      "Alternatively, here is another concise version:\n",
      "\n",
      "Generative AI enables the creation of new content based on learned patterns from data, with significant implications for fields like creative industries, where its applications are continually expanding.\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original prompt\n",
    "original_prompt = \"Summarize the following paragraph: Generative AI is a field of artificial intelligence focused on creating new content based on patterns learned from existing data. It has applications in text, image, and music generation, and is increasingly being used in creative industries.\"\n",
    "\n",
    "# ADD HERE YOUR PROMPT\n",
    "refined_prompt = (\n",
    "    \"Summarize the following paragraph in 2 concise sentences, focusing on the main goal \"\n",
    "    \"of Generative AI and its key application areas. Avoid repeating the original phrasing \"\n",
    "    \"and keep the tone informative and professional.\\n\\n\"\n",
    "    \"Paragraph: Generative AI is a field of artificial intelligence focused on creating new \"\n",
    "    \"content based on patterns learned from existing data. It has applications in text, image, \"\n",
    "    \"and music generation, and is increasingly being used in creative industries.\"\n",
    ")\n",
    "\n",
    "# Stream the responses and print them\n",
    "for idx, prompt in enumerate([original_prompt, refined_prompt]):\n",
    "    prompt_type = [\"Original Prompt\", \"Refined Prompt\"][idx]\n",
    "    print(f\"\\n--- {prompt_type} ---\\n\")\n",
    "    print(f\"User Prompt:\\n{prompt}\\n\")\n",
    "    \n",
    "    stream = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    print(\"Model Output:\")\n",
    "    for chunk in stream:\n",
    "        print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "    print(\"\\n-----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Task 4: Structured Prompting with Roles (Pirate Theme)\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Learn how to use structured prompts that combine role assignment, clear instructions, and examples to improve the output of language models. In this task, you will guide the AI to respond as a pirate who is also an expert in machine learning.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Role Assignment: In your prompt, specify the role of the AI as a Machine Learning Expert who speaks like a pirate.\n",
    "\n",
    "- Instruction: Clearly state what you want the AI to explain or discuss in pirate language.\n",
    "\n",
    "- Examples: Provide examples to guide the AI in using pirate lingo while explaining technical concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Techniques Prompt with Pirate Theme\n",
    "\n",
    "structured_prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "# Stream the response and print it\n",
    "print(\"=== User Prompt ===\")\n",
    "print(structured_prompt)\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": structured_prompt}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Model Output ===\")\n",
    "for chunk in stream:\n",
    "    print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
